{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wsFlXB2ntsL",
        "outputId": "47d1843f-9720-4ae6-bb26-5897f11dcd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved first 100 entries to ground_truth_with_labels.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Load the original JSON file\n",
        "with open('sample_data/ground_truth_with_labels.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract the first 100 entries\n",
        "first_100 = data[:100]\n",
        "\n",
        "# Save to new file\n",
        "with open('new_ground_truth_with_labels.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(first_100, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"Saved first 100 entries to ground_truth_with_labels.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "# Step 1: Load JSON file into DataFrame\n",
        "with open('sample_data/new_ground_truth_with_labels.json', 'r', encoding='utf-8') as f:\n",
        "    json_data = json.load(f)\n",
        "\n",
        "json_df = pd.DataFrame(json_data)\n",
        "\n",
        "# Step 2: Load Excel file into DataFrame\n",
        "xlsx_df = pd.read_excel('sample_data/Data.xlsx')  # change filename if needed\n",
        "\n",
        "# Step 3: Merge on matching ID columns\n",
        "merged_df = pd.merge(json_df, xlsx_df, how='inner', left_on='reviewId', right_on='ID')\n",
        "\n",
        "# Step 4: Drop rows where labels are missing in either file (optional, for clean comparison)\n",
        "merged_df = merged_df.dropna(subset=['label', 'Label'])\n",
        "\n",
        "# ðŸ”¹ Log how many entries were matched and considered\n",
        "print(f\"Total matched and evaluated entries: {len(merged_df)}\")\n",
        "\n",
        "# Step 5: Compute Evaluation Metrics\n",
        "true_labels = merged_df['label']\n",
        "pred_labels = merged_df['Label']\n",
        "\n",
        "accuracy = accuracy_score(true_labels, pred_labels)\n",
        "f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "recall = recall_score(true_labels, pred_labels, average='weighted')\n",
        "precision = precision_score(true_labels, pred_labels, average='weighted')\n",
        "\n",
        "# Step 6: Output metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPULhRSoo0i0",
        "outputId": "7c1c01d7-1c6e-4e11-86d6-14348136c157"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matched and evaluated entries: 97\n",
            "Accuracy: 0.4021\n",
            "F1 Score: 0.3490\n",
            "Recall: 0.4021\n",
            "Precision: 0.3765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVPUkh_Gp8PW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}